{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95be4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sk\n",
    "import pickle\n",
    "import mne\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "DEVICE='cuda'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658f9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_9804\\213190029.py:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  path=f'ds005540\\derivatives\\sub-0{sub}\\ses-vid\\eeg\\sub-0{sub}_ses-vid_task-emotion_reorder.npy'\n",
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_9804\\213190029.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  path=f'ds005540\\derivatives\\sub-0{sub}\\ses-vid\\eeg\\sub-0{sub}_ses-vid_task-emotion_reorder.npy'\n",
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_9804\\213190029.py:10: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  path=f'ds005540\\derivatives\\sub-{sub}\\ses-vid\\eeg\\sub-{sub}_ses-vid_task-emotion_reorder.npy'\n",
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_9804\\213190029.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  path=f'ds005540\\derivatives\\sub-{sub}\\ses-vid\\eeg\\sub-{sub}_ses-vid_task-emotion_reorder.npy'\n"
     ]
    }
   ],
   "source": [
    "def extract_data(sub_range,verbose=False,feature_func=None,**kwargs):\n",
    "    first=sub_range[0]\n",
    "    last=sub_range[-1]\n",
    "\n",
    "    for sub in trange(first,last+1): \n",
    "        #read data\n",
    "        if sub <=9:\n",
    "            path=f'ds005540\\derivatives\\sub-0{sub}\\ses-vid\\eeg\\sub-0{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        else:\n",
    "            path=f'ds005540\\derivatives\\sub-{sub}\\ses-vid\\eeg\\sub-{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        datatemp=np.load(path,allow_pickle=True)\n",
    "        datatemp=np.permute_dims(datatemp,[1,0,2])\n",
    "\n",
    "        #if we want to convert features\n",
    "        if not feature_func==None:\n",
    "            datatemp=feature_func(datatemp,info=info)\n",
    "\n",
    "        #cat data along new dimension\n",
    "        datatemp=torch.tensor(datatemp).unsqueeze(0)\n",
    "        if sub==first:\n",
    "            data=datatemp\n",
    "        else:\n",
    "            data=torch.cat([data,datatemp],axis=0)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'subject {sub} data extracted, vector size: {data.shape}')\n",
    "    return data\n",
    "\n",
    "def shuffle_and_split_data(X,y):\n",
    "    #get shuffled train/test/val in 8:1:1 ratio\n",
    "\n",
    "    N=X.size(0)\n",
    "    shuffled_indices=torch.randperm(N) #get shuffled indices\n",
    "    X=X[shuffled_indices]\n",
    "    y=y[shuffled_indices]\n",
    "\n",
    "    # split 80% train set\n",
    "    train_size=int(0.8*N)\n",
    "    X_train=X[:train_size]\n",
    "    y_train=y[:train_size]\n",
    "    X_rest=X[train_size:]\n",
    "    y_rest=y[train_size:]\n",
    "\n",
    "    #split remainder by half for test and val\n",
    "    splitind=int(len(X_rest)/2)\n",
    "    X_val=X_rest[:splitind]\n",
    "    y_val=y_rest[:splitind]\n",
    "    X_test=X_rest[splitind:]\n",
    "    y_test=y_rest[splitind:]\n",
    "\n",
    "    return X_test,y_test,X_val,y_val,X_train,y_train\n",
    "\n",
    "#create labels\n",
    "#sad-dis-fear-neu-joy-ten-ins correspond to 0-6 respectively, each sample has 21 trials, for (7 emotions x 3 trials)\n",
    "labels=np.array([])\n",
    "for i in range(0,7):\n",
    "    for n in range(0,3):\n",
    "        labels=np.concatenate([labels,np.array([i])],axis=0)\n",
    "labels=torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706e6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.21it/s]\n"
     ]
    }
   ],
   "source": [
    "data=extract_data([1,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca863e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    '''0-10s, 5-15s, 10-20s, 15-25, 20-30s ---> 5 samples per trial'''\n",
    "    for interval in tqdm.tqdm(range(0,5)):\n",
    "        datatrial=data[:,:,:,interval*1000:(interval+2)*1000]\n",
    "        datatrial=torch.unsqueeze(datatrial,2)\n",
    "        if interval==0:\n",
    "            newdata=datatrial\n",
    "        else:\n",
    "            newdata=torch.concatenate((newdata,datatrial),2)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44552c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 21, 5, 64, 2000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=process_data(data)\n",
    "data.shape #subject,label,trials,electrodes,timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f6794a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:09<00:00,  2.28it/s]\n",
      "100%|██████████| 30/30 [00:24<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3150, 64, 2000])\n",
      "torch.Size([3150, 1])\n",
      "torch.Size([315, 1, 64, 2000]) torch.Size([315]) torch.Size([315, 1, 64, 2000]) torch.Size([315]) torch.Size([2520, 1, 64, 2000]) torch.Size([2520])\n"
     ]
    }
   ],
   "source": [
    "for label in tqdm.tqdm(range(21)): #combine labels and trials\n",
    "    temp=data[:,label,:,:,:]\n",
    "    if label==0:\n",
    "        X=temp\n",
    "        y=labels[label]*torch.ones(5,1)\n",
    "    else:\n",
    "        X=torch.concatenate((X,temp),dim=1)\n",
    "        y=torch.concatenate((y,labels[label]*torch.ones(5,1)),dim=0)\n",
    "\n",
    "#combine subjects\n",
    "for subject in tqdm.tqdm(range(X.size(0))):\n",
    "    temp=X[subject,:,:,:]\n",
    "    if subject==0:\n",
    "        X_full=temp\n",
    "        y_full=y\n",
    "    else:\n",
    "        X_full=torch.concatenate((X_full,temp),dim=0)\n",
    "        y_full=torch.concatenate((y_full,y),dim=0)\n",
    "\n",
    "print(X_full.shape)\n",
    "print(y_full.shape)\n",
    "\n",
    "#split data\n",
    "X_test,y_test,X_val,y_val,X_train,y_train=shuffle_and_split_data(X_full.unsqueeze(1),y_full.squeeze())\n",
    "\n",
    "print(X_test.shape,y_test.shape,\n",
    "      X_val.shape,y_val.shape,\n",
    "      X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff9f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,dropouts):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,8,9,stride=1,padding=4)\n",
    "        self.conv2=nn.Conv2d(8,12,9,stride=1,padding=4)\n",
    "        self.conv3=nn.Conv2d(12,16,5,stride=1,padding=2)\n",
    "        self.conv4=nn.Conv2d(16,12,5,stride=1,padding=2)\n",
    "        self.conv5=nn.Conv2d(12,2,5,stride=1,padding=2)\n",
    "        self.pool1=nn.MaxPool2d(4)\n",
    "        self.fc1=nn.Linear(1000,350)\n",
    "        self.fc2=nn.Linear(350,350)\n",
    "        self.fc3=nn.Linear(350,7)\n",
    "        self.dropout1=nn.Dropout2d(dropouts[0])\n",
    "        self.dropout2=nn.Dropout(dropouts[1])\n",
    "        self.batchnorm1=nn.BatchNorm2d(8)\n",
    "        self.batchnorm2=nn.BatchNorm2d(12)\n",
    "        self.batchnorm3=nn.BatchNorm2d(16)\n",
    "        self.batchnorm4=nn.BatchNorm2d(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.batchnorm1(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.batchnorm2(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.batchnorm3(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.batchnorm2(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.batchnorm4(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.pool1(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.fc3(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "def train_test(net,epochs,train_loader,test_loader,device):\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.Adam(net.parameters(),lr=0.1)\n",
    "    train_acc=[]\n",
    "    train_loss=[]\n",
    "    test_acc=[]\n",
    "    test_loss=[]\n",
    "    net.to(device)\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        net.train()\n",
    "        running_loss=0.0\n",
    "        correct,total=0,0\n",
    "        for i,data in enumerate(train_loader,start=0):\n",
    "            inputs,labels=data\n",
    "            inputs=inputs.to(device).float()\n",
    "            labels=labels.to(device).long()\n",
    "            \n",
    "            #train\n",
    "            optimizer.zero_grad()\n",
    "            outputs=net.forward(inputs)\n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss+=loss.item()\n",
    "            #training accuracy\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum()\n",
    "        train_loss.append(running_loss/len(train_loader))\n",
    "        train_acc.append(correct/total)\n",
    "        print(f\"epoch {epoch} --> TRAIN loss: {running_loss/len(train_loader):.6f}, TRAIN accuracy: {correct/total:.2f}\")\n",
    "\n",
    "        #eval on test\n",
    "        net.eval()\n",
    "        running_loss=0.0\n",
    "        correct,total=0,0\n",
    "        for inputs,labels in test_loader:\n",
    "            inputs,labels=inputs.to(device).float(),labels.to(device).long()\n",
    "            outputs=net.forward(inputs)\n",
    "            loss=criterion(outputs,labels)\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "            #test acc\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum()\n",
    "        test_loss.append(running_loss/len(test_loader))\n",
    "        test_acc.append(correct/total)\n",
    "        print(f\"epoch {epoch} --> TEST loss: {running_loss/len(train_loader):.2f}, TEST accuracy: {correct/total:.2f}\")\n",
    "\n",
    "    return train_loss,train_acc,test_loss,test_acc\n",
    "\n",
    "\n",
    "batch_size=75\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
    "                         shuffle=False,num_workers=2\n",
    "                         )\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=False,\n",
    "                          shuffle=True,num_workers=2\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08785fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 --> TRAIN loss: 3.507743, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [00:35<35:13, 35.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 1 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [00:57<26:47, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 2 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [01:20<24:16, 25.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 3 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/60 [01:44<23:04, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 4 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [02:07<22:14, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 5 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [02:30<21:30, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 6 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [02:54<20:57, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 7 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8/60 [03:17<20:31, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 8 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9/60 [03:41<20:00, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 9 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10/60 [04:04<19:27, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 10 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [04:27<19:00, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 11 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [04:51<18:50, 23.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 --> TEST loss: 0.29, TEST accuracy: 0.10\n",
      "epoch 12 --> TRAIN loss: 1.945910, TRAIN accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [05:13<20:52, 26.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m net=Net(dropouts=[\u001b[32m0.4\u001b[39m,\u001b[32m0.4\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loss,train_acc,test_loss,test_acc=\u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mtrain_test\u001b[39m\u001b[34m(net, epochs, train_loader, test_loader, device)\u001b[39m\n\u001b[32m     92\u001b[39m running_loss=\u001b[32m0.0\u001b[39m\n\u001b[32m     93\u001b[39m correct,total=\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malco\\Documents\\cmn-templates\\sandbox\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malco\\Documents\\cmn-templates\\sandbox\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malco\\Documents\\cmn-templates\\sandbox\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\malco\\Documents\\cmn-templates\\sandbox\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\queues.py:111\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    110\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1096\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1093\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1094\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1028\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m   1027\u001b[39m     short_L = L[:\u001b[32m60\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L) > \u001b[32m60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m L\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshort_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1030\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "net=Net(dropouts=[0.4,0.4])\n",
    "train_loss,train_acc,test_loss,test_acc=train_test(net,60,train_loader=train_loader,test_loader=test_loader,device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

15/7/25: (MLP model) 672 training samples each with 6720 inputs (power spectrum of 14 chosen electrodes), three hidden layers of same size. The model can't seem to crack 25% test set accuracy even after 110 epochs.

180725:
class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1=nn.Conv2d(1,16,3,stride=1,padding=1)
        self.conv2=nn.Conv2d(16,12,3,stride=1,padding=1)
        self.conv3=nn.Conv2d(12,2,3,stride=1,padding=1)
        self.pool1=nn.MaxPool2d(4)
        self.pool2=nn.MaxPool2d(2)
        self.fc1=nn.Linear(400,200)
        self.fc2=nn.Linear(200,128)
        self.fc3=nn.Linear(128,7)
        self.dropout1=nn.Dropout2d(0.3)
        self.dropout2=nn.Dropout(0.2)
        self.batchnorm1=nn.BatchNorm2d(16)
        self.batchnorm2=nn.BatchNorm2d(12)

    def forward(self,x):
        x=self.conv1(x)
        x=self.batchnorm1(x)
        x=self.dropout1(x)
        x=nn.functional.relu(x)
        x=self.conv2(x)
        self.batchnorm2(x)
        x=self.dropout1(x)
        x=nn.functional.relu(x)
        x=self.pool1(x)
        x=self.conv3(x)
        x=self.dropout1(x)
        x=nn.functional.relu(x)
        x=self.pool2(x)
        x=torch.flatten(x,1)
        x=self.fc1(x)
        self.dropout2(x)
        x=nn.functional.relu(x)
        x=self.fc2(x)
        x=self.dropout2(x)
        x=nn.functional.relu(x)
        x=self.fc3(x)
        x=nn.functional.relu(x)
        return x
#max accuracy: 0.38 before it starts to overfit

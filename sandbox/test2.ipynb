{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95be4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sk\n",
    "import pickle\n",
    "import mne\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658f9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(sub_range,verbose=False,feature_func=None,**kwargs):\n",
    "    first=sub_range[0]\n",
    "    last=sub_range[-1]\n",
    "\n",
    "    for sub in trange(first,last+1): \n",
    "        #read data\n",
    "        if sub <=9:\n",
    "            path=f'/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-0{sub}/ses-vid/eeg/sub-0{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        else:\n",
    "            path=f'/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-{sub}/ses-vid/eeg/sub-{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        datatemp=np.load(path,allow_pickle=True)\n",
    "        datatemp=np.permute_dims(datatemp,[1,0,2])\n",
    "\n",
    "        #if we want to convert features\n",
    "        if not feature_func==None:\n",
    "            datatemp=feature_func(datatemp,info=info)\n",
    "\n",
    "        #cat data along new dimension\n",
    "        datatemp=torch.tensor(datatemp).unsqueeze(0)\n",
    "        if sub==first:\n",
    "            data=datatemp\n",
    "        else:\n",
    "            data=torch.cat([data,datatemp],axis=0)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'subject {sub} data extracted, vector size: {data.shape}')\n",
    "    return data\n",
    "\n",
    "def shuffle_and_split_data(X,y):\n",
    "    \"\"\"\n",
    "    Helper function to shuffle and split data\n",
    "\n",
    "    Args:\n",
    "        X: torch.tensor\n",
    "        Input data\n",
    "        y: torch.tensor\n",
    "        Corresponding target variables\n",
    "        seed: int\n",
    "        Set seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        X_test: torch.tensor\n",
    "        Test data [20% of X]\n",
    "        y_test: torch.tensor\n",
    "        Labels corresponding to above mentioned test data\n",
    "        X_train: torch.tensor\n",
    "        Train data [80% of X]\n",
    "        y_train: torch.tensor\n",
    "        Labels corresponding to above mentioned train data\n",
    "    \"\"\"\n",
    "    \n",
    "    N=X.size(0)\n",
    "    shuffled_indices=torch.randperm(N) #get shuffled indices\n",
    "    X=X[shuffled_indices]\n",
    "    y=y[shuffled_indices]\n",
    "\n",
    "    # split by 20% into train-test set\n",
    "    test_size=int(0.2*N)\n",
    "    X_train=X[test_size:]\n",
    "    y_train=y[test_size:]\n",
    "    X_test=X[:test_size]\n",
    "    y_test=y[:test_size]\n",
    "\n",
    "    return X_test,y_test,X_train,y_train\n",
    "\n",
    "#create labels\n",
    "#sad-dis-fear-neu-joy-ten-ins correspond to 1-7 respectively, each sample has 21 trials, for (7 emotions x 3 trials)\n",
    "labels=np.array([])\n",
    "for i in range(1,8):\n",
    "    for n in range(0,3):\n",
    "        labels=np.concatenate([labels,np.array([i])],axis=0)\n",
    "labels=torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706e6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.32it/s]\n"
     ]
    }
   ],
   "source": [
    "data=extract_data([1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca863e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    '''further process into trials (1 second trials, 200 points)'''\n",
    "    for trial in tqdm.tqdm(range(int(data.size(3)/200))):\n",
    "        datatrial=data[:,:,:,trial*200:(trial+1)*200]\n",
    "        datatrial=torch.unsqueeze(datatrial,2)\n",
    "        if trial==0:\n",
    "            newdata=datatrial\n",
    "        else:\n",
    "            newdata=torch.concatenate((newdata,datatrial),2)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44552c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 23.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 21, 30, 64, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=process_data(data)\n",
    "data.shape #subject,label,trials,electrodes,timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f6794a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 23.65it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3150, 64, 200])\n",
      "torch.Size([3150, 1])\n",
      "torch.Size([630, 1, 64, 200]) torch.Size([630]) torch.Size([2520, 1, 64, 200]) torch.Size([2520])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for label in tqdm.tqdm(range(21)): #combine labels and trials\n",
    "    temp=data[:,label,:,:,:]\n",
    "    if label==0:\n",
    "        X=temp\n",
    "        y=labels[label]*torch.ones(30,1)\n",
    "    else:\n",
    "        X=torch.concatenate((X,temp),dim=1)\n",
    "        y=torch.concatenate((y,labels[label]*torch.ones(30,1)),dim=0)\n",
    "\n",
    "#combine subjects\n",
    "for subject in tqdm.tqdm(range(X.size(0))):\n",
    "    temp=X[subject,:,:,:]\n",
    "    if subject==0:\n",
    "        X_full=temp\n",
    "        y_full=y\n",
    "    else:\n",
    "        X_full=torch.concatenate((X_full,temp),dim=0)\n",
    "        y_full=torch.concatenate((y_full,y),dim=0)\n",
    "\n",
    "print(X_full.shape)\n",
    "print(y_full.shape)\n",
    "\n",
    "#split data\n",
    "X_test,y_test,X_train,y_train=shuffle_and_split_data(X_full.unsqueeze(1),y_full.squeeze())\n",
    "\n",
    "print(X_test.shape,y_test.shape,X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff9f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,32,3,stride=1,padding=1)\n",
    "        self.conv2=nn.Conv2d(32,16,3,stride=1,padding=1)\n",
    "        self.fc1=nn.Linear(16*12800,128)\n",
    "        self.fc2=nn.Linear(128,7)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.fc1(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "def train_test(net,epochs,train_loader,test_loader,device):\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.Adam(net.parameters(),lr=3e-4)\n",
    "    train_acc=[]\n",
    "    train_loss=[]\n",
    "    test_acc=[]\n",
    "    test_loss=[]\n",
    "    net.to(device)\n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        net.train()\n",
    "        running_loss=0.0\n",
    "        correct,total=0,0\n",
    "        for i,data in enumerate(train_loader,start=0):\n",
    "            inputs,labels=data\n",
    "            inputs=inputs.to(device).float()\n",
    "            labels=labels.to(device)\n",
    "            \n",
    "\n",
    "            #train\n",
    "            optimizer.zero_grad()\n",
    "            outputs=net.forward(inputs)\n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss+=loss.item()\n",
    "            #training accuracy\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum()\n",
    "        train_loss.append(running_loss/len(train_loader))\n",
    "        train_acc.append(correct/total)\n",
    "        print(f\"epoch {epoch} --> TRAIN loss: {running_loss/len(train_loader)}, TRAIN accuracy: {correct/total}\")\n",
    "\n",
    "        #eval on test\n",
    "        net.eval()\n",
    "        running_loss=0.0\n",
    "        correct,total=0,0\n",
    "        for inputs,labels in test_loader:\n",
    "            inputs,labels=inputs.to(device),labels.to(device)\n",
    "            outputs=net.forward(inputs)\n",
    "            loss=criterion(outputs,labels)\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "            #test acc\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum()\n",
    "        test_loss.append(running_loss/len(test_loader))\n",
    "        test_acc.append(correct/total)\n",
    "        print(f\"epoch {epoch} --> TEST loss: {running_loss/len(train_loader)}, TEST accuracy: {correct/total}\")\n",
    "\n",
    "    return train_loss,train_acc,test_loss,test_acc\n",
    "\n",
    "\n",
    "batch_size=150\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
    "                         shuffle=False\n",
    "                         )\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=False,\n",
    "                          shuffle=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08785fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "m_device->CreateOperator(&opDesc, IID_PPV_ARGS(&op))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m net=Net()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_loss,train_acc,test_loss,test_acc=\u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mtrain_test\u001b[39m\u001b[34m(net, epochs, train_loader, test_loader, device)\u001b[39m\n\u001b[32m     42\u001b[39m optimizer.zero_grad()\n\u001b[32m     43\u001b[39m outputs=net.forward(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m loss=\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m loss.backward()\n\u001b[32m     46\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytdml2/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytdml2/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytdml2/lib/python3.12/site-packages/torch/nn/modules/loss.py:1188\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytdml2/lib/python3.12/site-packages/torch/nn/functional.py:3104\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3103\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: m_device->CreateOperator(&opDesc, IID_PPV_ARGS(&op))"
     ]
    }
   ],
   "source": [
    "net=Net()\n",
    "train_loss,train_acc,test_loss,test_acc=train_test(net,10,train_loader=train_loader,test_loader=test_loader,device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

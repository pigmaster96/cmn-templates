{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf676d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sk\n",
    "import pickle\n",
    "import mne\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch_directml\n",
    "DEVICE = torch_directml.device()\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52210ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 64, 6000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.load('/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-01/ses-vid/eeg/sub-01_ses-vid_task-emotion_reorder.npy',allow_pickle=True)\n",
    "data=np.permute_dims(data,[1,0,2])\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c1b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21, 64, 480)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature conversion from preprocessed signal to power spectrum, welch method with default params\n",
    "data=np.load('/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-01/ses-vid/eeg/sub-01_ses-vid_task-emotion_reorder.npy',allow_pickle=True)\n",
    "data=np.permute_dims(data,[1,0,2])\n",
    "data.shape\n",
    "\n",
    "cnames=['Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
    "'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8',\n",
    "'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10']\n",
    "info=mne.create_info(cnames,200,'eeg')\n",
    "\n",
    "def eeg_to_spectrum(eeg,info):\n",
    "    epochs=mne.EpochsArray(data,info)\n",
    "    out=epochs.compute_psd(method='welch',fmin=0.1,fmax=47,verbose=None).get_data()\n",
    "    return out\n",
    "\n",
    "temp=eeg_to_spectrum(data,info=info)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4535e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames=['Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3','AF4','AF8', 'F7', 'F5','F3','F1','Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "'FT7', 'FC5', 'FC3', 'FC1','FCz','FC2','FC4', 'FC6', 'FT8', 'T7','C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
    "'TP7', 'CP5', 'CP3', 'CP1','CPz','CP2', 'CP4','CP6', 'TP8', 'P7','P5', 'P3', 'P1', 'Pz','P2', 'P4', 'P6', 'P8',\n",
    "'PO7', 'PO3','POz', 'PO4','PO8', 'O1','Oz','O2', 'F9', 'F10', 'TP9', 'TP10']\n",
    "info=mne.create_info(cnames,200,'eeg')\n",
    "\n",
    "#feature conversion from preprocessed signal to power spectrum, welch method with default params\n",
    "def eeg_to_spectrum(eeg,info):\n",
    "    epochs=mne.EpochsArray(eeg,info)\n",
    "    out=epochs.compute_psd(method='welch',fmin=0.1,fmax=47,verbose=None).get_data()\n",
    "    return out\n",
    "\n",
    "\n",
    "#now create input vector\n",
    "#14/7/25: Kernel keeps crashing when iterating from subject 1 to 54 in one go,\n",
    "#this doesn't happen when iterating from 1-25 or 30-54... maybe the vector is too large?\n",
    "def extract_data(sub_range,verbose=False,feature_func=None,**kwargs):\n",
    "    first=sub_range[0]\n",
    "    last=sub_range[-1]\n",
    "\n",
    "    for sub in trange(first,last+1): \n",
    "        #read data\n",
    "        if sub <=9:\n",
    "            path=f'/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-0{sub}/ses-vid/eeg/sub-0{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        else:\n",
    "            path=f'/home/pigmaster96/openneuroNMAdata/ds005540-download/derivatives/sub-{sub}/ses-vid/eeg/sub-{sub}_ses-vid_task-emotion_reorder.npy'\n",
    "        datatemp=np.load(path,allow_pickle=True)\n",
    "        datatemp=np.permute_dims(datatemp,[1,0,2])\n",
    "\n",
    "        #if we want to convert features\n",
    "        if not feature_func==None:\n",
    "            datatemp=feature_func(datatemp,info=info)\n",
    "\n",
    "        #cat data along new dimension\n",
    "        datatemp=torch.tensor(datatemp).unsqueeze(0)\n",
    "        if sub==first:\n",
    "            data=datatemp\n",
    "        else:\n",
    "            data=torch.cat([data,datatemp],axis=0)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'subject {sub} data extracted, vector size: {data.shape}')\n",
    "    return data\n",
    "\n",
    "\n",
    "#create labels\n",
    "#sad-dis-fear-neu-joy-ten-ins correspond to 1-7 respectively, each sample has 21 trials, for (7 emotions x 3 trials)\n",
    "labels=np.array([])\n",
    "for i in range(1,8):\n",
    "    for n in range(0,3):\n",
    "        labels=np.concatenate([labels,np.array([i])],axis=0)\n",
    "\n",
    "\n",
    "#extract one CNN input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f3fd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP with power spectrum and channels\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, actv, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "        \"\"\"\n",
    "        Initialize MLP Network parameters\n",
    "\n",
    "        Args:\n",
    "        actv: string\n",
    "            Activation function\n",
    "        input_feature_num: int\n",
    "            Number of input features\n",
    "        hidden_unit_nums: list\n",
    "            Number of units per hidden layer. List of integers\n",
    "        output_feature_num: int\n",
    "            Number of output features\n",
    "\n",
    "        Returns:\n",
    "        Nothing\n",
    "        \"\"\"\n",
    "        super(Net,self).__init__()\n",
    "        self.input_feature_num=input_feature_num\n",
    "        self.mlp=nn.Sequential()\n",
    "\n",
    "        in_num=input_feature_num #input at any given point in time\n",
    "        for i in range(len(hidden_unit_nums)):\n",
    "            out_num=hidden_unit_nums[i]\n",
    "            layer=nn.Linear(in_num,out_num) #define linear layer\n",
    "            in_num=out_num #update input to next layer\n",
    "            self.mlp.add_module(f\"Linear_{i}\",layer) #add to sequential\n",
    "\n",
    "            actv_layer=eval(f\"nn.{actv}\")\n",
    "            self.mlp.add_module(f\"Activation_{i}\",actv_layer) #append activation\n",
    "\n",
    "        out_layer=nn.Linear(in_num,output_feature_num) #create output layer\n",
    "        self.mlp.add_module(f\"Output_linear\", out_layer) #append output layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Simulate forward pass of MLP Network\n",
    "\n",
    "        Args:\n",
    "        x: torch.tensor\n",
    "            Input data\n",
    "\n",
    "        Returns:\n",
    "        logits: Instance of MLP\n",
    "            Forward pass of MLP\n",
    "        \"\"\"\n",
    "        logits=self.mlp(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_test_classification(net, criterion, optimizer, train_loader,\n",
    "                              test_loader, num_epochs=1, verbose=True,\n",
    "                              training_plot=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    Accumulate training loss/Evaluate performance\n",
    "\n",
    "    Args:\n",
    "        net: Instance of Net class\n",
    "        Describes the model with ReLU activation, batch size 128\n",
    "        criterion: torch.nn type\n",
    "        Criterion combines LogSoftmax and NLLLoss in one single class.\n",
    "        optimizer: torch.optim type\n",
    "        Implements Adam algorithm.\n",
    "        train_loader: torch.utils.data type\n",
    "        Combines the train dataset and sampler, and provides an iterable over the given dataset.\n",
    "        test_loader: torch.utils.data type\n",
    "        Combines the test dataset and sampler, and provides an iterable over the given dataset.\n",
    "        num_epochs: int\n",
    "        Number of epochs [default: 1]\n",
    "        verbose: boolean\n",
    "        If True, print statistics\n",
    "        training_plot=False\n",
    "        If True, display training plot\n",
    "        device: string\n",
    "        CUDA/GPU if available, CPU otherwise\n",
    "\n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    training_losses=[]\n",
    "    for epoch in trange(num_epochs): #loop over epochs\n",
    "        for i, data in enumerate(train_loader, start=0):\n",
    "            # Get the inputs; data is a list of [inputs, labels]\n",
    "            inputs,labels=data\n",
    "            inputs=inputs.to(device).float()\n",
    "            labels=labels.to(device).long()\n",
    "\n",
    "            #zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward pass, backprop, optimize\n",
    "            outputs=net.forward(inputs)\n",
    "            \n",
    "            loss=criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            if verbose:\n",
    "                training_losses += [loss.item()]\n",
    "    net.eval()\n",
    "\n",
    "    def test(data_loader):\n",
    "        \"\"\"\n",
    "        Function to gauge network performance\n",
    "\n",
    "        Args:\n",
    "        data_loader: torch.utils.data type\n",
    "            Combines the test dataset and sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "        Returns:\n",
    "        acc: float\n",
    "            Performance of the network\n",
    "        total: int\n",
    "            Number of datapoints in the dataloader\n",
    "        \"\"\"\n",
    "        correct=0\n",
    "        total=0\n",
    "        for data in data_loader:\n",
    "            inputs,labels=data\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            outputs=net(inputs)\n",
    "            _,predicted=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum()\n",
    "        \n",
    "        acc=100*correct/total\n",
    "        return total,acc\n",
    "    \n",
    "    train_total,train_acc=test(train_loader)\n",
    "    test_total,test_acc=test(test_loader)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'\\nAccuracy on the {train_total} training samples: {train_acc:0.2f}')\n",
    "        print(f'Accuracy on the {test_total} testing samples: {test_acc:0.2f}\\n')\n",
    "\n",
    "    if training_plot:\n",
    "        plt.plot(training_losses)\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Training loss')\n",
    "        plt.show()\n",
    "    return train_acc,test_acc\n",
    "\n",
    "def shuffle_and_split_data(X,y,seed):\n",
    "    \"\"\"\n",
    "    Helper function to shuffle and split data\n",
    "\n",
    "    Args:\n",
    "        X: torch.tensor\n",
    "        Input data\n",
    "        y: torch.tensor\n",
    "        Corresponding target variables\n",
    "        seed: int\n",
    "        Set seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        X_test: torch.tensor\n",
    "        Test data [20% of X]\n",
    "        y_test: torch.tensor\n",
    "        Labels corresponding to above mentioned test data\n",
    "        X_train: torch.tensor\n",
    "        Train data [80% of X]\n",
    "        y_train: torch.tensor\n",
    "        Labels corresponding to above mentioned train data\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    N=X.size(0)\n",
    "    shuffled_indices=torch.randperm(N) #get shuffled indices\n",
    "    X=X[shuffled_indices]\n",
    "    y=y[shuffled_indices]\n",
    "\n",
    "    # split by 20% into train-test set\n",
    "    test_size=int(0.2*N)\n",
    "    X_train=X[test_size:]\n",
    "    y_train=y[test_size:]\n",
    "    X_test=X[:test_size]\n",
    "    y_test=y[:test_size]\n",
    "\n",
    "    return X_test,y_test,X_train,y_train\n",
    "\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ed4de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:17,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:01<00:18,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:01<00:18,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:02<00:17,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:02<00:16,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:03<00:16,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [00:04<00:16,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [00:04<00:16,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [00:05<00:15,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [00:05<00:16,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [00:06<00:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [00:06<00:15,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [00:07<00:14,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [00:08<00:14,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [00:08<00:13,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [00:09<00:12,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [00:09<00:11,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [00:10<00:11,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [00:10<00:10,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [00:11<00:09,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [00:11<00:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [00:12<00:09,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [00:12<00:08,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [00:13<00:07,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [00:13<00:07,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [00:14<00:06,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [00:14<00:06,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [00:15<00:05,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [00:15<00:05,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [00:16<00:04,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [00:17<00:04,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [00:17<00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [00:18<00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [00:18<00:02,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [00:19<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [00:19<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [00:20<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [00:20<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "21 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Effective window size : 10.240 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:21<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_1=extract_data([1,40],feature_func=eeg_to_spectrum,info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c420e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=['AF3','AF4','F7','F3','F4','F8','FC5','FC6','T7','T8','P7','P8','O1','O2']\n",
    "chaninds=[]\n",
    "for chan in channels:\n",
    "    chaninds.append(cnames.index(chan))\n",
    "data_1=data_1[:,:,chaninds,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0824e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in range(data_1.size(0)):\n",
    "    if patient==0:\n",
    "        X=data_1[patient,:,:,:]\n",
    "        y=labels\n",
    "    else:\n",
    "        X=np.concatenate((X,data_1[patient,:,:,:]),axis=0)\n",
    "        y=np.concatenate((y,labels),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71720aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 14, 480)\n",
      "(840,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2794932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2025 has been set.\n",
      "6720 inputs\n",
      "torch.Size([168, 6720])\n",
      "torch.Size([672, 6720])\n"
     ]
    }
   ],
   "source": [
    "#data for one patient\n",
    "SEED=2025\n",
    "set_seed(SEED)\n",
    "\n",
    "X=torch.tensor(X).squeeze().flatten(1,2)\n",
    "y=torch.tensor(y)\n",
    "X_test, y_test, X_train, y_train = shuffle_and_split_data(X,y,seed=SEED)\n",
    "print(f\"{X.size(1)} inputs\")\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c54d5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=400\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
    "                         shuffle=False, num_workers=0,\n",
    "                         worker_init_fn=seed_worker,\n",
    "                         generator=g_seed,\n",
    "                         )\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=False,\n",
    "                          shuffle=True,\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g_seed,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc9d7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(epochs):\n",
    "    train_acc_vec=[]\n",
    "    test_acc_vec=[]\n",
    "    for epoch in epochs:\n",
    "        net=Net('ReLU()',6720,[6720,6720,6720],7).to(DEVICE)\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "        optimizer=optim.Adam(net.parameters(),lr=3e-4)\n",
    "\n",
    "        train_acc,test_acc=train_test_classification(net, criterion, optimizer,\n",
    "                                    train_loader, test_loader,\n",
    "                                    num_epochs=epoch, device=DEVICE)\n",
    "        train_acc_vec.append(train_acc)\n",
    "        test_acc_vec.append(test_acc)\n",
    "    return train_acc_vec,test_acc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21bb6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 17.71\n",
      "Accuracy on the 168 testing samples: 11.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:49<00:00,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 37.65\n",
      "Accuracy on the 168 testing samples: 8.93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:14<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 67.11\n",
      "Accuracy on the 168 testing samples: 12.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:41<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 77.53\n",
      "Accuracy on the 168 testing samples: 13.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:59<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 11.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:16<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 10.12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:40<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 14.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:08<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 77.23\n",
      "Accuracy on the 168 testing samples: 20.24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [03:44<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 84.82\n",
      "Accuracy on the 168 testing samples: 14.29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:06<00:00,  4.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 84.52\n",
      "Accuracy on the 168 testing samples: 17.26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [04:37<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 13.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [04:48<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 20.83\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [05:15<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 14.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [05:29<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 16.07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [05:48<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 13.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [06:12<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 11.90\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [06:38<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 14.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [06:52<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 11.31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [07:08<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 84.23\n",
      "Accuracy on the 168 testing samples: 14.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:31<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 12.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [07:51<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 13.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [08:18<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 6.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [08:48<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the 672 training samples: 85.42\n",
      "Accuracy on the 168 testing samples: 8.93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/120 [00:08<16:48,  8.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/adam.py:534\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_lerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown error -2147467259",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs_to_test\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_acc_vec,test_acc_vec\u001b[38;5;241m=\u001b[39m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_to_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_acc_vec)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_acc_vec)\n",
      "Cell \u001b[0;32mIn[51], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-4\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m train_acc,test_acc\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_test_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m train_acc_vec\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[1;32m     13\u001b[0m test_acc_vec\u001b[38;5;241m.\u001b[39mappend(test_acc)\n",
      "Cell \u001b[0;32mIn[44], line 100\u001b[0m, in \u001b[0;36mtrain_test_classification\u001b[0;34m(net, criterion, optimizer, train_loader, test_loader, num_epochs, verbose, training_plot, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m loss\u001b[38;5;241m=\u001b[39mcriterion(outputs,labels)\n\u001b[1;32m     99\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 100\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytdml/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_to_test=np.arange(5,200,5)\n",
    "train_acc_vec,test_acc_vec=main(epochs_to_test)\n",
    "print(train_acc_vec)\n",
    "print(test_acc_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytdml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
